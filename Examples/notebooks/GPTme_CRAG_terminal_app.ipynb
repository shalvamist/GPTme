{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://github.com/shalvamist/GPTme/blob/main/Examples/notebooks/GPTme_CRAG_terminal_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ttnULFf-qLx"
      },
      "source": [
        "# Running Ollama + Corrective RAG in Colab\n",
        "\n",
        "### This example will show how to use GPTme package to run a corrective RAG using LangGraph.\n",
        "\n",
        "###### Credit to Langchain Blog for the CRAG logic - https://blog.langchain.dev/agentic-rag-with-langgraph/\n",
        "\n",
        "###### Credit to Gruff and his post on StackOverflow for making Ollama run in colab -\n",
        "https://stackoverflow.com/questions/77697302/how-to-run-ollama-in-google-colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIqt0wF1NlNK"
      },
      "source": [
        "# Setting up GPTme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSVwVAGxFYOB",
        "outputId": "0ec70fb4-0d92-43e4-c137-a9e6a00de267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.4.24)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.20.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.1.12)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.0.28)\n",
            "Requirement already satisfied: ollama in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.1.7)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.1.32)\n",
            "Requirement already satisfied: BeautifulSoup4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.12.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.5.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.32.2)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.0.28)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.12.6)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (1.1.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (2.6.4)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (0.110.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (4.10.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (1.15.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (1.23.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (0.15.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (4.66.2)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (6.1.1)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (1.62.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (4.1.2)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (29.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 1)) (3.9.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 2)) (2024.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 3)) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 3)) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 3)) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 3)) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 3)) (1.33)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 3)) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 3)) (0.1.26)\n",
            "Requirement already satisfied: httpx<0.26.0,>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from ollama->-r requirements.txt (line 5)) (0.25.2)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain_core->-r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from BeautifulSoup4->-r requirements.txt (line 7)) (2.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 8)) (4.37.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 8)) (2.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 8)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 8)) (1.10.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 8)) (10.2.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit->-r requirements.txt (line 9)) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (8.1.7)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (2.2.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (4.23.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (13.7.1)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (0.10.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (3.1.42)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 9)) (4.0.0)\n",
            "Requirement already satisfied: backoff==2.2.1 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2.2.1)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2024.2.2)\n",
            "Requirement already satisfied: chardet==5.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (3.3.2)\n",
            "Requirement already satisfied: dataclasses-json-speakeasy==0.5.11 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.5.11)\n",
            "Requirement already satisfied: emoji==2.10.1 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2.10.1)\n",
            "Requirement already satisfied: filetype==1.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: idna==3.6 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (3.6)\n",
            "Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.3.2)\n",
            "Requirement already satisfied: jsonpath-python==1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.0.6)\n",
            "Requirement already satisfied: langdetect==1.0.9 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.0.9)\n",
            "Requirement already satisfied: lxml==5.1.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (5.1.0)\n",
            "Requirement already satisfied: marshmallow==3.20.2 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (3.20.2)\n",
            "Requirement already satisfied: mypy-extensions==1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.0.0)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: python-iso639==2024.2.7 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2024.2.7)\n",
            "Requirement already satisfied: python-magic==0.4.27 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.4.27)\n",
            "Requirement already satisfied: rapidfuzz==3.6.1 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (3.6.1)\n",
            "Requirement already satisfied: regex==2023.12.25 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2023.12.25)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.9.0)\n",
            "Collecting typing-extensions>=4.5.0 (from chromadb->-r requirements.txt (line 1))\n",
            "  Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: typing-inspect==0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.9.0)\n",
            "Requirement already satisfied: unstructured-client==0.18.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.18.0)\n",
            "Requirement already satisfied: urllib3==1.26.18 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.26.18)\n",
            "Requirement already satisfied: wrapt==1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.3 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (4.9.3)\n",
            "Requirement already satisfied: cffi==1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: coloredlogs==15.0.1 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (15.0.1)\n",
            "Requirement already satisfied: contourpy==1.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: cryptography==42.0.2 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (42.0.2)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: deprecated==1.2.14 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.2.14)\n",
            "Requirement already satisfied: effdet==0.4.1 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.4.1)\n",
            "Requirement already satisfied: flatbuffers==23.5.26 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (23.5.26)\n",
            "Requirement already satisfied: fonttools==4.49.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (4.49.0)\n",
            "Requirement already satisfied: humanfriendly==10.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (10.0)\n",
            "Requirement already satisfied: iopath==0.1.10 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.1.10)\n",
            "Requirement already satisfied: jinja2==3.1.3 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (3.1.3)\n",
            "Requirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.4.5)\n",
            "Requirement already satisfied: layoutparser[layoutmodels,tesseract]==0.3.4 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.3.4)\n",
            "Requirement already satisfied: markupsafe==2.1.5 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib==3.7.2 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (3.7.2)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: networkx==3.2.1 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (3.2.1)\n",
            "Requirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2.3.0)\n",
            "Requirement already satisfied: onnx==1.15.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.15.0)\n",
            "Requirement already satisfied: opencv-python==4.8.0.76 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (4.8.0.76)\n",
            "Requirement already satisfied: pdf2image==1.17.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.17.0)\n",
            "Requirement already satisfied: pdfminer-six==20221105 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (20221105)\n",
            "Requirement already satisfied: pdfplumber==0.10.4 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.10.4)\n",
            "Requirement already satisfied: pikepdf==8.11.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (8.11.0)\n",
            "Requirement already satisfied: pillow-heif==0.15.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.15.0)\n",
            "Requirement already satisfied: portalocker==2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: pycocotools==2.0.7 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2.0.7)\n",
            "Requirement already satisfied: pycparser==2.21 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2.21)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (3.0.9)\n",
            "Requirement already satisfied: pypdf==4.0.1 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (4.0.1)\n",
            "Requirement already satisfied: pypdfium2==4.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (4.27.0)\n",
            "Requirement already satisfied: pytesseract==0.3.10 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.3.10)\n",
            "Requirement already satisfied: python-multipart==0.0.9 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.0.9)\n",
            "Requirement already satisfied: pytz==2024.1 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2024.1)\n",
            "Requirement already satisfied: safetensors==0.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.3.2)\n",
            "Requirement already satisfied: sympy==1.12 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (1.12)\n",
            "Requirement already satisfied: timm==0.9.12 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.9.12)\n",
            "Requirement already satisfied: torchvision==0.17.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.17.0)\n",
            "Requirement already satisfied: tzdata==2024.1 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (2024.1)\n",
            "Requirement already satisfied: unstructured-inference==0.7.23 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.7.23)\n",
            "Requirement already satisfied: unstructured-pytesseract==0.3.12 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (0.3.12)\n",
            "Requirement already satisfied: zipp==3.17.0 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 11)) (3.17.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 8)) (12.4.99)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain_core->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain_core->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 1)) (0.36.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 9)) (4.0.11)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->ollama->-r requirements.txt (line 5)) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.2->ollama->-r requirements.txt (line 5)) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain->-r requirements.txt (line 3)) (2.4)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 1)) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 1)) (6.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 1)) (1.63.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 1)) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 1)) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 1)) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 1)) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 1)) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 1)) (0.44b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 1)) (3.7.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 1)) (1.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb->-r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb->-r requirements.txt (line 1)) (2.16.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 9)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 9)) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 3)) (3.0.3)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 1)) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 1)) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 1)) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 1)) (12.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 9)) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 1)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r requirements.txt (line 9)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 1)) (0.5.1)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.10.0\n",
            "    Uninstalling typing_extensions-4.10.0:\n",
            "      Successfully uninstalled typing_extensions-4.10.0\n",
            "Successfully installed typing-extensions-4.9.0\n",
            "I ccache not found. Consider installing it for faster compilation.\n",
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion \n",
            "I CXXFLAGS:  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include \n",
            "I NVCCFLAGS: -std=c++11 -O3 -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 \n",
            "I LDFLAGS:   -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n",
            "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:       g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I NVCC:      Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "\n",
            "rm -vrf *.o tests/*.o *.so *.a *.dll benchmark-matmult common/build-info.cpp *.dot *.gcno tests/*.gcno *.gcda tests/*.gcda *.gcov tests/*.gcov lcov-report gcovr-report main quantize quantize-stats perplexity imatrix embedding vdot q8dot train-text-from-scratch convert-llama2c-to-ggml simple batched batched-bench save-load-state server gguf llama-bench libllava.a llava-cli baby-llama beam-search speculative infill tokenize benchmark-matmult parallel finetune export-lora lookahead lookup passkey gritlm tests/test-c.o tests/test-llama-grammar tests/test-grammar-parser tests/test-double-float tests/test-grad0 tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-sampling tests/test-tokenizer-0-llama tests/test-tokenizer-0-falcon tests/test-tokenizer-1-llama tests/test-tokenizer-1-bpe tests/test-rope tests/test-backend-ops tests/test-model-load-cancel tests/test-autorelease\n",
            "find examples pocs -type f -name \"*.o\" -delete\n",
            "I ccache not found. Consider installing it for faster compilation.\n",
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion \n",
            "I CXXFLAGS:  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include \n",
            "I NVCCFLAGS: -std=c++11 -O3 -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 \n",
            "I LDFLAGS:   -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n",
            "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:       g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I NVCC:      Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c llama.cpp -o llama.o\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml.c -o ggml.o\n",
            "nvcc -std=c++11 -O3 -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml-cuda.cu -o ggml-cuda.o\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml-alloc.c -o ggml-alloc.o\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml-backend.c -o ggml-backend.o\n",
            "cc -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion     -c ggml-quants.c -o ggml-quants.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c unicode.cpp -o unicode.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -shared -fPIC -o libllama.so llama.o ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n",
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.56.tar.gz (36.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.9/36.9 MB 209.6 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
            "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
            "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 286.1 MB/s eta 0:00:00\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.5/45.5 kB 148.3 MB/s eta 0:00:00\n",
            "Collecting jinja2>=2.11.3 (from llama-cpp-python)\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.2/133.2 kB 312.7 MB/s eta 0:00:00\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
            "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.56-cp310-cp310-manylinux_2_35_x86_64.whl size=26289877 sha256=f830b40d29cc7aca2bde360147259dcc1d244e28b337f944b9a40fe664faa30d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o6idhvvg/wheels/e5/09/9d/c413053f6258cb2546cc792418c595e276f9efd5db31a80377\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/__pycache__/typing_extensions.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions-4.9.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions.py\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Removing file or directory /usr/local/bin/f2py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy-1.26.4.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy/\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  changing mode of /usr/local/bin/f2py to 755\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/MarkupSafe-2.1.5.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/markupsafe/\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: diskcache\n",
            "    Found existing installation: diskcache 5.6.3\n",
            "    Uninstalling diskcache-5.6.3:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/diskcache-5.6.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/diskcache/\n",
            "      Successfully uninstalled diskcache-5.6.3\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.3\n",
            "    Uninstalling Jinja2-3.1.3:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/Jinja2-3.1.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/jinja2/\n",
            "      Successfully uninstalled Jinja2-3.1.3\n",
            "  Attempting uninstall: llama-cpp-python\n",
            "    Found existing installation: llama_cpp_python 0.2.56\n",
            "    Uninstalling llama_cpp_python-0.2.56:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/__pycache__/convert-lora-to-ggml.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/__pycache__/convert.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/convert-lora-to-ggml.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/convert.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/llava-cli\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/include/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/lib/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/llama_cpp/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/llama_cpp_python-0.2.56.dist-info/\n",
            "      Successfully uninstalled llama_cpp_python-0.2.56\n",
            "Successfully installed MarkupSafe-2.1.5 diskcache-5.6.3 jinja2-3.1.3 llama-cpp-python-0.2.56 numpy-1.26.4 typing-extensions-4.10.0\n",
            "Requirement already satisfied: build in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build) (2.0.1)\n",
            "* Creating venv isolated environment...\n",
            "* Installing packages in isolated environment... (setuptools)\n",
            "* Getting build dependencies for sdist...\n",
            "running egg_info\n",
            "writing GPTme.egg-info/PKG-INFO\n",
            "writing dependency_links to GPTme.egg-info/dependency_links.txt\n",
            "writing top-level names to GPTme.egg-info/top_level.txt\n",
            "reading manifest file 'GPTme.egg-info/SOURCES.txt'\n",
            "writing manifest file 'GPTme.egg-info/SOURCES.txt'\n",
            "* Building sdist...\n",
            "running sdist\n",
            "running egg_info\n",
            "writing GPTme.egg-info/PKG-INFO\n",
            "writing dependency_links to GPTme.egg-info/dependency_links.txt\n",
            "writing top-level names to GPTme.egg-info/top_level.txt\n",
            "reading manifest file 'GPTme.egg-info/SOURCES.txt'\n",
            "writing manifest file 'GPTme.egg-info/SOURCES.txt'\n",
            "running check\n",
            "creating GPTme-0.0.1\n",
            "creating GPTme-0.0.1/Examples\n",
            "creating GPTme-0.0.1/GPTme\n",
            "creating GPTme-0.0.1/GPTme.egg-info\n",
            "creating GPTme-0.0.1/GPTme/agents\n",
            "creating GPTme-0.0.1/GPTme/ingest\n",
            "creating GPTme-0.0.1/GPTme/llms\n",
            "creating GPTme-0.0.1/GPTme/pipes\n",
            "creating GPTme-0.0.1/GPTme/streamlit_app\n",
            "copying files to GPTme-0.0.1...\n",
            "copying README.md -> GPTme-0.0.1\n",
            "copying pyproject.toml -> GPTme-0.0.1\n",
            "copying Examples/crag_example.py -> GPTme-0.0.1/Examples\n",
            "copying GPTme/config.py -> GPTme-0.0.1/GPTme\n",
            "copying GPTme/prompt_config.py -> GPTme-0.0.1/GPTme\n",
            "copying GPTme.egg-info/PKG-INFO -> GPTme-0.0.1/GPTme.egg-info\n",
            "copying GPTme.egg-info/SOURCES.txt -> GPTme-0.0.1/GPTme.egg-info\n",
            "copying GPTme.egg-info/dependency_links.txt -> GPTme-0.0.1/GPTme.egg-info\n",
            "copying GPTme.egg-info/top_level.txt -> GPTme-0.0.1/GPTme.egg-info\n",
            "copying GPTme/agents/Agentstools.py -> GPTme-0.0.1/GPTme/agents\n",
            "copying GPTme/agents/__init__.py -> GPTme-0.0.1/GPTme/agents\n",
            "copying GPTme/agents/crewagent.py -> GPTme-0.0.1/GPTme/agents\n",
            "copying GPTme/ingest/__init__.py -> GPTme-0.0.1/GPTme/ingest\n",
            "copying GPTme/ingest/database.py -> GPTme-0.0.1/GPTme/ingest\n",
            "copying GPTme/ingest/load_webpage.py -> GPTme-0.0.1/GPTme/ingest\n",
            "copying GPTme/llms/__init__.py -> GPTme-0.0.1/GPTme/llms\n",
            "copying GPTme/llms/hf_load_model.py -> GPTme-0.0.1/GPTme/llms\n",
            "copying GPTme/llms/ollama_load_model.py -> GPTme-0.0.1/GPTme/llms\n",
            "copying GPTme/pipes/__init__.py -> GPTme-0.0.1/GPTme/pipes\n",
            "copying GPTme/pipes/llama_cpp_deploy.py -> GPTme-0.0.1/GPTme/pipes\n",
            "copying GPTme/pipes/local_crag.py -> GPTme-0.0.1/GPTme/pipes\n",
            "copying GPTme/pipes/rag_chain.py -> GPTme-0.0.1/GPTme/pipes\n",
            "copying GPTme/streamlit_app/crag_app.py -> GPTme-0.0.1/GPTme/streamlit_app\n",
            "copying GPTme/streamlit_app/rag_app.py -> GPTme-0.0.1/GPTme/streamlit_app\n",
            "copying GPTme.egg-info/SOURCES.txt -> GPTme-0.0.1/GPTme.egg-info\n",
            "Writing GPTme-0.0.1/setup.cfg\n",
            "Creating tar archive\n",
            "removing 'GPTme-0.0.1' (and everything under it)\n",
            "* Building wheel from sdist\n",
            "* Creating venv isolated environment...\n",
            "* Installing packages in isolated environment... (setuptools)\n",
            "* Getting build dependencies for wheel...\n",
            "running egg_info\n",
            "writing GPTme.egg-info/PKG-INFO\n",
            "writing dependency_links to GPTme.egg-info/dependency_links.txt\n",
            "writing top-level names to GPTme.egg-info/top_level.txt\n",
            "reading manifest file 'GPTme.egg-info/SOURCES.txt'\n",
            "writing manifest file 'GPTme.egg-info/SOURCES.txt'\n",
            "* Installing packages in isolated environment... (wheel)\n",
            "* Building wheel...\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/GPTme\n",
            "copying GPTme/config.py -> build/lib/GPTme\n",
            "copying GPTme/prompt_config.py -> build/lib/GPTme\n",
            "creating build/lib/Examples\n",
            "copying Examples/crag_example.py -> build/lib/Examples\n",
            "creating build/lib/GPTme/agents\n",
            "copying GPTme/agents/__init__.py -> build/lib/GPTme/agents\n",
            "copying GPTme/agents/crewagent.py -> build/lib/GPTme/agents\n",
            "copying GPTme/agents/Agentstools.py -> build/lib/GPTme/agents\n",
            "creating build/lib/GPTme/pipes\n",
            "copying GPTme/pipes/rag_chain.py -> build/lib/GPTme/pipes\n",
            "copying GPTme/pipes/local_crag.py -> build/lib/GPTme/pipes\n",
            "copying GPTme/pipes/__init__.py -> build/lib/GPTme/pipes\n",
            "copying GPTme/pipes/llama_cpp_deploy.py -> build/lib/GPTme/pipes\n",
            "creating build/lib/GPTme/llms\n",
            "copying GPTme/llms/ollama_load_model.py -> build/lib/GPTme/llms\n",
            "copying GPTme/llms/__init__.py -> build/lib/GPTme/llms\n",
            "copying GPTme/llms/hf_load_model.py -> build/lib/GPTme/llms\n",
            "creating build/lib/GPTme/ingest\n",
            "copying GPTme/ingest/database.py -> build/lib/GPTme/ingest\n",
            "copying GPTme/ingest/__init__.py -> build/lib/GPTme/ingest\n",
            "copying GPTme/ingest/load_webpage.py -> build/lib/GPTme/ingest\n",
            "creating build/lib/GPTme/streamlit_app\n",
            "copying GPTme/streamlit_app/crag_app.py -> build/lib/GPTme/streamlit_app\n",
            "copying GPTme/streamlit_app/rag_app.py -> build/lib/GPTme/streamlit_app\n",
            "running egg_info\n",
            "writing GPTme.egg-info/PKG-INFO\n",
            "writing dependency_links to GPTme.egg-info/dependency_links.txt\n",
            "writing top-level names to GPTme.egg-info/top_level.txt\n",
            "reading manifest file 'GPTme.egg-info/SOURCES.txt'\n",
            "writing manifest file 'GPTme.egg-info/SOURCES.txt'\n",
            "installing to build/bdist.linux-x86_64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/wheel\n",
            "creating build/bdist.linux-x86_64/wheel/GPTme\n",
            "creating build/bdist.linux-x86_64/wheel/GPTme/agents\n",
            "copying build/lib/GPTme/agents/__init__.py -> build/bdist.linux-x86_64/wheel/GPTme/agents\n",
            "copying build/lib/GPTme/agents/crewagent.py -> build/bdist.linux-x86_64/wheel/GPTme/agents\n",
            "copying build/lib/GPTme/agents/Agentstools.py -> build/bdist.linux-x86_64/wheel/GPTme/agents\n",
            "copying build/lib/GPTme/config.py -> build/bdist.linux-x86_64/wheel/GPTme\n",
            "creating build/bdist.linux-x86_64/wheel/GPTme/pipes\n",
            "copying build/lib/GPTme/pipes/rag_chain.py -> build/bdist.linux-x86_64/wheel/GPTme/pipes\n",
            "copying build/lib/GPTme/pipes/local_crag.py -> build/bdist.linux-x86_64/wheel/GPTme/pipes\n",
            "copying build/lib/GPTme/pipes/__init__.py -> build/bdist.linux-x86_64/wheel/GPTme/pipes\n",
            "copying build/lib/GPTme/pipes/llama_cpp_deploy.py -> build/bdist.linux-x86_64/wheel/GPTme/pipes\n",
            "creating build/bdist.linux-x86_64/wheel/GPTme/llms\n",
            "copying build/lib/GPTme/llms/ollama_load_model.py -> build/bdist.linux-x86_64/wheel/GPTme/llms\n",
            "copying build/lib/GPTme/llms/__init__.py -> build/bdist.linux-x86_64/wheel/GPTme/llms\n",
            "copying build/lib/GPTme/llms/hf_load_model.py -> build/bdist.linux-x86_64/wheel/GPTme/llms\n",
            "creating build/bdist.linux-x86_64/wheel/GPTme/ingest\n",
            "copying build/lib/GPTme/ingest/database.py -> build/bdist.linux-x86_64/wheel/GPTme/ingest\n",
            "copying build/lib/GPTme/ingest/__init__.py -> build/bdist.linux-x86_64/wheel/GPTme/ingest\n",
            "copying build/lib/GPTme/ingest/load_webpage.py -> build/bdist.linux-x86_64/wheel/GPTme/ingest\n",
            "copying build/lib/GPTme/prompt_config.py -> build/bdist.linux-x86_64/wheel/GPTme\n",
            "creating build/bdist.linux-x86_64/wheel/GPTme/streamlit_app\n",
            "copying build/lib/GPTme/streamlit_app/crag_app.py -> build/bdist.linux-x86_64/wheel/GPTme/streamlit_app\n",
            "copying build/lib/GPTme/streamlit_app/rag_app.py -> build/bdist.linux-x86_64/wheel/GPTme/streamlit_app\n",
            "creating build/bdist.linux-x86_64/wheel/Examples\n",
            "copying build/lib/Examples/crag_example.py -> build/bdist.linux-x86_64/wheel/Examples\n",
            "running install_egg_info\n",
            "Copying GPTme.egg-info to build/bdist.linux-x86_64/wheel/GPTme-0.0.1-py3.10.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.linux-x86_64/wheel/GPTme-0.0.1.dist-info/WHEEL\n",
            "creating '/content/GPTme/dist/.tmp-sh_4nwpk/GPTme-0.0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "adding 'Examples/crag_example.py'\n",
            "adding 'GPTme/config.py'\n",
            "adding 'GPTme/prompt_config.py'\n",
            "adding 'GPTme/agents/Agentstools.py'\n",
            "adding 'GPTme/agents/__init__.py'\n",
            "adding 'GPTme/agents/crewagent.py'\n",
            "adding 'GPTme/ingest/__init__.py'\n",
            "adding 'GPTme/ingest/database.py'\n",
            "adding 'GPTme/ingest/load_webpage.py'\n",
            "adding 'GPTme/llms/__init__.py'\n",
            "adding 'GPTme/llms/hf_load_model.py'\n",
            "adding 'GPTme/llms/ollama_load_model.py'\n",
            "adding 'GPTme/pipes/__init__.py'\n",
            "adding 'GPTme/pipes/llama_cpp_deploy.py'\n",
            "adding 'GPTme/pipes/local_crag.py'\n",
            "adding 'GPTme/pipes/rag_chain.py'\n",
            "adding 'GPTme/streamlit_app/crag_app.py'\n",
            "adding 'GPTme/streamlit_app/rag_app.py'\n",
            "adding 'GPTme-0.0.1.dist-info/METADATA'\n",
            "adding 'GPTme-0.0.1.dist-info/WHEEL'\n",
            "adding 'GPTme-0.0.1.dist-info/top_level.txt'\n",
            "adding 'GPTme-0.0.1.dist-info/RECORD'\n",
            "removing build/bdist.linux-x86_64/wheel\n",
            "Successfully built GPTme-0.0.1.tar.gz and GPTme-0.0.1-py3-none-any.whl\n",
            "Obtaining file:///content/GPTme\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Checking if build backend supports build_editable: started\n",
            "  Checking if build backend supports build_editable: finished with status 'done'\n",
            "  Getting requirements to build editable: started\n",
            "  Getting requirements to build editable: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing editable metadata (pyproject.toml): started\n",
            "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
            "Building wheels for collected packages: GPTme\n",
            "  Building editable for GPTme (pyproject.toml): started\n",
            "  Building editable for GPTme (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for GPTme: filename=GPTme-0.0.1-0.editable-py3-none-any.whl size=2612 sha256=1cdd383aee76a0ae57c5fe5d33ee45bcaf506eda35513683907b2cc575d07b01\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4pxg3dmh/wheels/e0/d9/52/1b4a3c79c5daf2bdf31bb3d87ead95b8e40669c0ff836d4089\n",
            "Successfully built GPTme\n",
            "Installing collected packages: GPTme\n",
            "  Attempting uninstall: GPTme\n",
            "    Found existing installation: GPTme 0.0.1\n",
            "    Uninstalling GPTme-0.0.1:\n",
            "      Successfully uninstalled GPTme-0.0.1\n",
            "Successfully installed GPTme-0.0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'GPTme' already exists and is not an empty directory.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.24.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.2.0 which is incompatible.\n",
            "fatal: destination path 'llama.cpp' already exists and is not an empty directory.\n",
            "  Running command pip subprocess to install build dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting scikit-build-core[pyproject]>=0.5.1\n",
            "    Using cached scikit_build_core-0.8.2-py3-none-any.whl (140 kB)\n",
            "  Collecting exceptiongroup (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
            "  Collecting packaging>=20.9 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
            "  Collecting tomli>=1.1 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "  Collecting pathspec>=0.10.1 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "  Collecting pyproject-metadata>=0.5 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached pyproject_metadata-0.7.1-py3-none-any.whl (7.4 kB)\n",
            "  Installing collected packages: tomli, pathspec, packaging, exceptiongroup, scikit-build-core, pyproject-metadata\n",
            "  ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "  langchain-core 0.1.32 requires packaging<24.0,>=23.2, but you have packaging 24.0 which is incompatible.\n",
            "  streamlit 1.32.2 requires packaging<24,>=16.8, but you have packaging 24.0 which is incompatible.\n",
            "  tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\n",
            "  unstructured 0.12.6 requires packaging==23.2, but you have packaging 24.0 which is incompatible.\n",
            "  Successfully installed exceptiongroup-1.2.0 packaging-24.0 pathspec-0.12.1 pyproject-metadata-0.7.1 scikit-build-core-0.8.2 tomli-2.0.1\n",
            "  Running command Getting requirements to build wheel\n",
            "  Running command pip subprocess to install backend dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting cmake>=3.21\n",
            "    Using cached cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
            "  Collecting ninja>=1.5\n",
            "    Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "  Installing collected packages: ninja, cmake\n",
            "    Creating /tmp/pip-build-env-qghmur9a/normal/local/bin\n",
            "    changing mode of /tmp/pip-build-env-qghmur9a/normal/local/bin/ninja to 755\n",
            "    changing mode of /tmp/pip-build-env-qghmur9a/normal/local/bin/cmake to 755\n",
            "    changing mode of /tmp/pip-build-env-qghmur9a/normal/local/bin/cpack to 755\n",
            "    changing mode of /tmp/pip-build-env-qghmur9a/normal/local/bin/ctest to 755\n",
            "  Successfully installed cmake-3.28.3 ninja-1.11.1.1\n",
            "  Running command Preparing metadata (pyproject.toml)\n",
            "  *** scikit-build-core 0.8.2 using CMake 3.28.3 (metadata_wheel)\n",
            "  Running command Building wheel for llama-cpp-python (pyproject.toml)\n",
            "  *** scikit-build-core 0.8.2 using CMake 3.28.3 (wheel)\n",
            "  *** Configuring CMake...\n",
            "  loading initial cache file /tmp/tmpvtxi_lqv/build/CMakeInit.txt\n",
            "  -- The C compiler identification is GNU 11.4.0\n",
            "  -- The CXX compiler identification is GNU 11.4.0\n",
            "  -- Detecting C compiler ABI info\n",
            "  -- Detecting C compiler ABI info - done\n",
            "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
            "  -- Detecting C compile features\n",
            "  -- Detecting C compile features - done\n",
            "  -- Detecting CXX compiler ABI info\n",
            "  -- Detecting CXX compiler ABI info - done\n",
            "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "  -- Detecting CXX compile features\n",
            "  -- Detecting CXX compile features - done\n",
            "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "  -- Found Threads: TRUE\n",
            "  -- Found CUDAToolkit: /usr/local/cuda-12.2/targets/x86_64-linux/include (found version \"12.2.140\")\n",
            "  -- cuBLAS found\n",
            "  -- The CUDA compiler identification is NVIDIA 12.2.140\n",
            "  -- Detecting CUDA compiler ABI info\n",
            "  -- Detecting CUDA compiler ABI info - done\n",
            "  -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "  -- Detecting CUDA compile features\n",
            "  -- Detecting CUDA compile features - done\n",
            "  -- Using CUDA architectures: 52;61;70\n",
            "  -- CUDA host compiler is GNU 11.4.0\n",
            "\n",
            "  -- Warning: ccache not found - consider installing it for faster compilation or disable this warning with LLAMA_CCACHE=OFF\n",
            "  -- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "  -- x86 detected\n",
            "  CMake Warning (dev) at CMakeLists.txt:21 (install):\n",
            "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n",
            "  This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\n",
            "  CMake Warning (dev) at CMakeLists.txt:30 (install):\n",
            "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n",
            "  This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\n",
            "  -- Configuring done (3.1s)\n",
            "  -- Generating done (0.0s)\n",
            "  CMake Warning:\n",
            "    Manually-specified variables were not used by the project:\n",
            "\n",
            "      CUDAToolkit_INCLUDE_DIR\n",
            "      CUDA_PATH\n",
            "\n",
            "\n",
            "  -- Build files have been written to: /tmp/tmpvtxi_lqv/build\n",
            "  *** Building project with Ninja...\n",
            "  Change Dir: '/tmp/tmpvtxi_lqv/build'\n",
            "\n",
            "  Run Build Command(s): /tmp/pip-build-env-qghmur9a/normal/local/lib/python3.10/dist-packages/ninja/data/bin/ninja -v\n",
            "  [1/23] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -isystem /usr/local/cuda-12.2/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/ggml-alloc.c\n",
            "  [2/23] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -isystem /usr/local/cuda-12.2/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/ggml-backend.c\n",
            "  [3/23] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -isystem /usr/local/cuda-12.2/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/ggml-quants.c\n",
            "  [4/23] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -isystem /usr/local/cuda-12.2/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/ggml.c\n",
            "  [5/23] cd /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp && /tmp/pip-build-env-qghmur9a/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -DMSVC= -DCMAKE_C_COMPILER_VERSION=11.4.0 -DCMAKE_C_COMPILER_ID=GNU -DCMAKE_VS_PLATFORM_NAME= -DCMAKE_C_COMPILER=/usr/bin/cc -P /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/../scripts/gen-build-info-cpp.cmake\n",
            "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "  [6/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600  -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/build-info.cpp\n",
            "  [7/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/common.cpp\n",
            "  [8/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/sampling.cpp\n",
            "  [9/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/console.cpp\n",
            "  [10/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/grammar-parser.cpp\n",
            "  [11/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/train.cpp\n",
            "  [12/23] /usr/bin/c++ -DGGML_USE_CUBLAS -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -isystem /usr/local/cuda-12.2/targets/x86_64-linux/include -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/llava.cpp\n",
            "  [13/23] /usr/bin/c++ -DGGML_USE_CUBLAS -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -isystem /usr/local/cuda-12.2/targets/x86_64-linux/include -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/clip.cpp\n",
            "  [14/23] : && /tmp/pip-build-env-qghmur9a/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/examples/llava/libllava_static.a && /usr/bin/ar qc vendor/llama.cpp/examples/llava/libllava_static.a  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o && /usr/bin/ranlib vendor/llama.cpp/examples/llava/libllava_static.a && :\n",
            "  [15/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -DLLAMA_BUILD -DLLAMA_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dllama_EXPORTS -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -isystem /usr/local/cuda-12.2/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -MF vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o.d -o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/llama.cpp\n",
            "  [16/23] /usr/bin/c++ -DGGML_USE_CUBLAS -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/common/. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/../../common -O3 -DNDEBUG -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/examples/llava/llava-cli.cpp\n",
            "  [17/23] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/. -isystem /usr/local/cuda-12.2/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o.d -x cu -c /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/vendor/llama.cpp/ggml-cuda.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o\n",
            "  [18/23] : && /tmp/pip-build-env-qghmur9a/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/libggml_static.a && /usr/bin/ar qc vendor/llama.cpp/libggml_static.a  vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o && /usr/bin/ranlib vendor/llama.cpp/libggml_static.a && :\n",
            "  [19/23] : && /usr/bin/g++ -fPIC  -shared -Wl,-soname,libggml_shared.so -o vendor/llama.cpp/libggml_shared.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o  /usr/local/cuda-12.2/lib64/libcudart.so  /usr/local/cuda-12.2/lib64/libcublas.so  /usr/local/cuda-12.2/lib64/libcublasLt.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/stubs/libcuda.so  /usr/local/cuda-12.2/lib64/libculibos.a  -lcudadevrt  -lcudart_static  -lrt  -lpthread  -ldl -L\"/usr/local/cuda/targets/x86_64-linux/lib/stubs\" -L\"/usr/local/cuda/targets/x86_64-linux/lib\" && :\n",
            "  [20/23] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllama.so -o vendor/llama.cpp/libllama.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -L/usr/local/cuda/targets/x86_64-linux/lib -Wl,-rpath,/usr/local/cuda-12.2/lib64:  /usr/local/cuda-12.2/lib64/libcudart.so  /usr/local/cuda-12.2/lib64/libcublas.so  /usr/local/cuda-12.2/lib64/libcublasLt.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/stubs/libcuda.so  /usr/local/cuda-12.2/lib64/libculibos.a  -lcudadevrt  -lcudart_static  -lrt  -lpthread  -ldl && :\n",
            "  [21/23] : && /tmp/pip-build-env-qghmur9a/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/common/libcommon.a && /usr/bin/ar qc vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o && /usr/bin/ranlib vendor/llama.cpp/common/libcommon.a && :\n",
            "  [22/23] : && /usr/bin/c++ -O3 -DNDEBUG  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -o vendor/llama.cpp/examples/llava/llava-cli  -Wl,-rpath,/tmp/tmpvtxi_lqv/build/vendor/llama.cpp:/usr/local/cuda-12.2/lib64:  vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/libllama.so  /usr/local/cuda-12.2/lib64/libcudart.so  /usr/local/cuda-12.2/lib64/libcublas.so  /usr/local/cuda-12.2/lib64/libculibos.a  /usr/local/cuda-12.2/lib64/libcublasLt.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/stubs/libcuda.so && :\n",
            "  [23/23] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllava.so -o vendor/llama.cpp/examples/llava/libllava.so vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o  -Wl,-rpath,/tmp/tmpvtxi_lqv/build/vendor/llama.cpp:/usr/local/cuda-12.2/lib64:  vendor/llama.cpp/libllama.so  /usr/local/cuda-12.2/lib64/libcudart.so  /usr/local/cuda-12.2/lib64/libcublas.so  /usr/local/cuda-12.2/lib64/libculibos.a  /usr/local/cuda-12.2/lib64/libcublasLt.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/stubs/libcuda.so && :\n",
            "\n",
            "  *** Installing project into wheel...\n",
            "  -- Install configuration: \"Release\"\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/lib/libggml_shared.so\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/lib/cmake/Llama/LlamaConfig.cmake\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/lib/cmake/Llama/LlamaConfigVersion.cmake\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/include/ggml.h\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/include/ggml-alloc.h\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/include/ggml-backend.h\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/include/ggml-cuda.h\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/lib/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpvtxi_lqv/wheel/platlib/lib/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/include/llama.h\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/bin/convert.py\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/bin/convert-lora-to-ggml.py\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/llama_cpp/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpvtxi_lqv/wheel/platlib/llama_cpp/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/llama_cpp/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/llama_cpp/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/lib/libllava.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpvtxi_lqv/wheel/platlib/lib/libllava.so\" to \"\"\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/bin/llava-cli\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpvtxi_lqv/wheel/platlib/bin/llava-cli\" to \"\"\n",
            "  -- Installing: /tmp/tmpvtxi_lqv/wheel/platlib/llama_cpp/libllava.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpvtxi_lqv/wheel/platlib/llama_cpp/libllava.so\" to \"\"\n",
            "  -- Installing: /tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/llama_cpp/libllava.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-m9q9r6fo/llama-cpp-python_f38d97847d064317b51792b9f7dca3ff/llama_cpp/libllava.so\" to \"\"\n",
            "  *** Making wheel...\n",
            "  *** Created llama_cpp_python-0.2.56-cp310-cp310-manylinux_2_35_x86_64.whl...\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.24.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.0 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.2.0 which is incompatible.\n",
            "unstructured 0.12.6 requires typing-extensions==4.9.0, but you have typing-extensions 4.10.0 which is incompatible.\n",
            ">>> Downloading ollama...\n",
            "#=#=- #                                                                                            \r\r############################################################################################# 100.0%##O=#  #                                                                                           \r#-#O=#   #                                                                                         \r\r                                                                                                0.0%\r                                                                                                0.5%\r#                                                                                               1.8%\r####                                                                                            4.8%\r##########                                                                                     11.6%\r####################                                                                           21.9%\r###########################                                                                    29.9%\r#####################################                                                          40.7%\r################################################                                               51.9%\r#########################################################                                      62.3%\r####################################################################                           74.0%\r##########################################################################                     80.3%\r###############################################################################                85.2%\r#######################################################################################        94.6%\r############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "System has not been booted with systemd as init system (PID 1). Can't operate.\n",
            "Failed to connect to bus: Host is down\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "git clone https://github.com/shalvamist/GPTme.git\n",
        "cd GPTme/\n",
        "source setup.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWNkF7vsAY8r"
      },
      "source": [
        "# Installing Ngrok & Ollama\n",
        "\n",
        "#### In order to run Ollama in Colab you will need a Ngrok key - it's free (for now)\n",
        "#### Sign up here and get your dev key - https://ngrok.com/\n",
        "#### Fill in the key in the second cell 'token=...'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzGDozdfBzDO",
        "outputId": "323781be-4ad8-4161-d254-b578ee8616b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "lshw is already the newest version (02.19.git.2021.06.19.996aaad9c7-2build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            ">>> Downloading ollama...\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "!sudo apt-get install lshw\n",
        "# Download and run the Ollama Linux install script\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AGI5AYetBvS1"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import time\n",
        "import os\n",
        "import asyncio\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "from threading import Thread\n",
        "\n",
        "# Get your ngrok token from your ngrok account:\n",
        "# https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "token=\"YOUR KEY GORS HERE\"\n",
        "ngrok.set_auth_token(token)\n",
        "\n",
        "# set up a stoppable thread (not mandatory, but cleaner if you want to stop this later\n",
        "class StoppableThread(threading.Thread):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(StoppableThread, self).__init__(*args, **kwargs)\n",
        "        self._stop_event = threading.Event()\n",
        "\n",
        "    def stop(self):\n",
        "        self._stop_event.set()\n",
        "\n",
        "    def is_stopped(self):\n",
        "        return self._stop_event.is_set()\n",
        "\n",
        "def start_ngrok(q, stop_event):\n",
        "    try:\n",
        "        # Start an HTTP tunnel on the specified port\n",
        "        public_url = ngrok.connect(11434)\n",
        "        # Put the public URL in the queue\n",
        "        q.put(public_url)\n",
        "        # Keep the thread alive until stop event is set\n",
        "        while not stop_event.is_set():\n",
        "            time.sleep(1)  # Adjust sleep time as needed\n",
        "    except Exception as e:\n",
        "        print(f\"Error in start_ngrok: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnBmg_-1B8Ed",
        "outputId": "3dc8bb49-5df6-4008-8337-5123c753216b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-03-15T23:11:39+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in start_ngrok: 'function' object has no attribute 'is_set'Ngrok tunnel established at: NgrokTunnel: \"https://ba0e-34-32-173-22.ngrok-free.app\" -> \"http://localhost:11434\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a queue to share data between threads\n",
        "url_queue = queue.Queue()\n",
        "\n",
        "# Start ngrok in a separate thread\n",
        "ngrok_thread = StoppableThread(target=start_ngrok, args=(url_queue, StoppableThread.is_stopped))\n",
        "ngrok_thread.start()\n",
        "\n",
        "# Wait for the ngrok tunnel to be established\n",
        "while True:\n",
        "    try:\n",
        "        public_url = url_queue.get()\n",
        "        if public_url:\n",
        "            break\n",
        "        print(\"Waiting for ngrok URL...\")\n",
        "        time.sleep(1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in retrieving ngrok URL: {e}\")\n",
        "\n",
        "print(\"Ngrok tunnel established at:\", public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "syREtA12CBg2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import asyncio\n",
        "\n",
        "# NB: You may need to set these depending and get cuda working depending which backend you are running.\n",
        "# Set environment variable for NVIDIA library\n",
        "# Set environment variables for CUDA\n",
        "os.environ['PATH'] += ':/usr/local/cuda/bin'\n",
        "# Set LD_LIBRARY_PATH to include both /usr/lib64-nvidia and CUDA lib directories\n",
        "# os.environ['LD_LIBRARY_PATH'] = '/usr/lib64-nvidia:/usr/local/cuda/lib64'\n",
        "\n",
        "async def run_process(cmd):\n",
        "    print('>>> starting', *cmd)\n",
        "    process = await asyncio.create_subprocess_exec(\n",
        "        *cmd,\n",
        "        stdout=asyncio.subprocess.PIPE,\n",
        "        stderr=asyncio.subprocess.PIPE\n",
        "    )\n",
        "\n",
        "    # define an async pipe function\n",
        "    async def pipe(lines):\n",
        "        async for line in lines:\n",
        "            print(line.decode().strip())\n",
        "\n",
        "        await asyncio.gather(\n",
        "            pipe(process.stdout),\n",
        "            pipe(process.stderr),\n",
        "        )\n",
        "\n",
        "    # call it\n",
        "    await asyncio.gather(pipe(process.stdout), pipe(process.stderr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dVl6CdmCCd-",
        "outputId": "a9c94f63-24d9-4d18-95cd-0b60ace9bfad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> starting ollama serve\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import threading\n",
        "\n",
        "async def start_ollama_serve():\n",
        "    await run_process(['ollama', 'serve'])\n",
        "\n",
        "def run_async_in_thread(loop, coro):\n",
        "    asyncio.set_event_loop(loop)\n",
        "    loop.run_until_complete(coro)\n",
        "    loop.close()\n",
        "\n",
        "# Create a new event loop that will run in a new thread\n",
        "new_loop = asyncio.new_event_loop()\n",
        "\n",
        "# Start ollama serve in a separate thread so the cell won't block execution\n",
        "thread = threading.Thread(target=run_async_in_thread, args=(new_loop, start_ollama_serve()))\n",
        "thread.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWYt9Nu-B4Ci"
      },
      "source": [
        "# Pulling Ollama Mistral - This might take a few min\n",
        "\n",
        "#### you can pull any model you want available from Ollama - https://ollama.com/library\n",
        "\n",
        "#### I recommend to wait 5 min till the model download & verification is done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEke0eFNCFUG",
        "outputId": "07e34ca5-cb58-4cc9-b39a-589a0783fcfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> starting ollama pull mistral:instruct\n"
          ]
        }
      ],
      "source": [
        "async def ollama_pull(model=\"mistral:instruct\"):\n",
        "    await run_process(['ollama', 'pull', model])\n",
        "\n",
        "def run_async_in_thread(loop, coro):\n",
        "    asyncio.set_event_loop(loop)\n",
        "    loop.run_until_complete(coro)\n",
        "    loop.close()\n",
        "\n",
        "# Create a new event loop that will run in a new thread\n",
        "new_loop = asyncio.new_event_loop()\n",
        "\n",
        "# Start ollama serve in a separate thread so the cell won't block execution\n",
        "thread = threading.Thread(target=run_async_in_thread, args=(new_loop, ollama_pull()))\n",
        "thread.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgYBa9c-YczY",
        "outputId": "922aed1b-e3cd-43d9-d064-0052f7243bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[GIN] 2024/03/15 - 23:12:46 | 200 |      35.928µs |       127.0.0.1 | HEAD     \"/\"\n",
            "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h[GIN] 2024/03/15 - 23:12:47 | 200 |  1.290638279s |       127.0.0.1 | POST     \"/api/pull\"\n",
            "\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \u001b[?25h\n",
            "Error: pull model manifest: file does not exist\n"
          ]
        }
      ],
      "source": [
        "!ollama pull mistal:instruct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnjjiTY_WKeD"
      },
      "source": [
        "# Corrective RAG (CRAG) app\n",
        "\n",
        "#### This is a simple CRAG graph, you can find the whole pipe under GPTme/pipes/loacl_crag.py\n",
        "#### There are two main retrievers (MMR, Similarity) that are being used to generate context, the LLM will generate a response only if it deciedes it has enough relevant context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ67KMqURMLk",
        "outputId": "cffc380c-c9df-43a6-8616-0a24aa15d9b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello I am here to help you find answers from your documentation.\n",
            "Please let me know what you would like to know. to end our conversation please enter 'bye'\n",
            "User entry - hello\n",
            "---RETRIEVE---\n",
            "Importing: riscv-spec-v2.2.pdf\n",
            "/content/GPTme/GPTme/../SOURCE_DOCS/riscv-spec-v2.2.pdf loaded.\n",
            "\n",
            "Building DB from sources - using embedding model BAAI/bge-base-en-v1.5\n",
            "\"Node 'mmr_retrieve':\"\n",
            "'\\n---\\n'\n",
            "---CHECK RELEVANCE---\n",
            "Using Langchin to mount mistral:instruct with Ollama\n",
            "time=2024-03-15T23:13:47.933Z level=INFO source=cpu_common.go:11 msg=\"CPU has AVX2\"\n",
            "time=2024-03-15T23:13:47.934Z level=INFO source=gpu.go:119 msg=\"CUDA Compute Capability detected: 7.5\"\n",
            "time=2024-03-15T23:13:47.934Z level=INFO source=cpu_common.go:11 msg=\"CPU has AVX2\"\n",
            "time=2024-03-15T23:13:47.934Z level=INFO source=gpu.go:119 msg=\"CUDA Compute Capability detected: 7.5\"\n",
            "time=2024-03-15T23:13:47.934Z level=INFO source=cpu_common.go:11 msg=\"CPU has AVX2\"\n",
            "time=2024-03-15T23:13:47.951Z level=INFO source=dyn_ext_server.go:90 msg=\"Loading Dynamic llm server: /tmp/ollama4011034817/runners/cuda_v11/libext_server.so\"\n",
            "time=2024-03-15T23:13:47.951Z level=INFO source=dyn_ext_server.go:150 msg=\"Initializing llama server\"\n",
            "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   yes\n",
            "ggml_init_cublas: CUDA_USE_TENSOR_CORES: no\n",
            "ggml_init_cublas: found 1 CUDA devices:\n",
            "Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /root/.ollama/models/blobs/sha256:e8a35b5937a5e6d5c35d1f2a15f161e07eefe5e5bb0a3cdd42998ee79b057730 (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,58980]   = [\"▁ t\", \"i n\", \"e r\", \"▁ a\", \"h e...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 1000000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_0\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 3.83 GiB (4.54 BPW)\n",
            "llm_load_print_meta: general.name     = mistralai\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  3847.55 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: freq_base  = 1000000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host input buffer size   =    13.02 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   164.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     8.00 MiB\n",
            "llama_new_context_with_model: graph splits (measure): 2\n",
            "loading library /tmp/ollama4011034817/runners/cuda_v11/libext_server.so\n",
            "{\"function\":\"initialize\",\"level\":\"INFO\",\"line\":440,\"msg\":\"initializing slots\",\"n_slots\":1,\"tid\":\"132316642920000\",\"timestamp\":1710544449}\n",
            "{\"function\":\"initialize\",\"level\":\"INFO\",\"line\":449,\"msg\":\"new slot\",\"n_ctx_slot\":2048,\"slot_id\":0,\"tid\":\"132316642920000\",\"timestamp\":1710544449}\n",
            "time=2024-03-15T23:14:09.936Z level=INFO source=dyn_ext_server.go:162 msg=\"Starting llama main loop\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1590,\"msg\":\"all slots are idle and system prompt is empty, clear the KV cache\",\"tid\":\"132314544727616\",\"timestamp\":1710544449}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":0,\"tid\":\"132314544727616\",\"timestamp\":1710544449}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":0,\"n_past_se\":0,\"n_prompt_tokens_processed\":663,\"slot_id\":0,\"task_id\":0,\"tid\":\"132314544727616\",\"timestamp\":1710544449}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":0,\"slot_id\":0,\"task_id\":0,\"tid\":\"132314544727616\",\"timestamp\":1710544449}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    1264.99 ms /   663 tokens (    1.91 ms per token,   524.11 tokens per second)\",\"n_prompt_tokens_processed\":663,\"n_tokens_second\":524.1131578489701,\"slot_id\":0,\"t_prompt_processing\":1264.994,\"t_token\":1.9079849170437404,\"task_id\":0,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     134.80 ms /     7 runs   (   19.26 ms per token,    51.93 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":51.9272425150589,\"slot_id\":0,\"t_token\":19.257714285714286,\"t_token_generation\":134.804,\"task_id\":0,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    1399.80 ms\",\"slot_id\":0,\"t_prompt_processing\":1264.994,\"t_token_generation\":134.804,\"t_total\":1399.798,\"task_id\":0,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":670,\"n_ctx\":2048,\"n_past\":669,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":0,\"tid\":\"132314544727616\",\"timestamp\":1710544451,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:14:11 | 200 | 24.156222313s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":10,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":663,\"n_past_se\":0,\"n_prompt_tokens_processed\":0,\"slot_id\":0,\"task_id\":10,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"we have to evaluate at least 1 token to generate logits\",\"slot_id\":0,\"task_id\":10,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":662,\"slot_id\":0,\"task_id\":10,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =      41.26 ms /     0 tokens (     inf ms per token,     0.00 tokens per second)\",\"n_prompt_tokens_processed\":0,\"n_tokens_second\":0.0,\"slot_id\":0,\"t_prompt_processing\":41.264,\"t_token\":null,\"task_id\":10,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     132.42 ms /     7 runs   (   18.92 ms per token,    52.86 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":52.861307033574484,\"slot_id\":0,\"t_token\":18.91742857142857,\"t_token_generation\":132.422,\"task_id\":10,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     173.69 ms\",\"slot_id\":0,\"t_prompt_processing\":41.264,\"t_token_generation\":132.422,\"t_total\":173.686,\"task_id\":10,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "[GIN] 2024/03/15 - 23:14:11 | 200 |  177.062178ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":670,\"n_ctx\":2048,\"n_past\":669,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":10,\"tid\":\"132314544727616\",\"timestamp\":1710544451,\"truncated\":false}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":20,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":661,\"slot_id\":0,\"task_id\":20,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":20,\"tid\":\"132314544727616\",\"timestamp\":1710544451}\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    1226.06 ms /   661 tokens (    1.85 ms per token,   539.12 tokens per second)\",\"n_prompt_tokens_processed\":661,\"n_tokens_second\":539.1235694058385,\"slot_id\":0,\"t_prompt_processing\":1226.064,\"t_token\":1.8548623298033284,\"task_id\":20,\"tid\":\"132314544727616\",\"timestamp\":1710544452}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     133.90 ms /     7 runs   (   19.13 ms per token,    52.28 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":52.27781926811053,\"slot_id\":0,\"t_token\":19.12857142857143,\"t_token_generation\":133.9,\"task_id\":20,\"tid\":\"132314544727616\",\"timestamp\":1710544452}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    1359.96 ms\",\"slot_id\":0,\"t_prompt_processing\":1226.064,\"t_token_generation\":133.9,\"t_total\":1359.9640000000002,\"task_id\":20,\"tid\":\"132314544727616\",\"timestamp\":1710544452}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":707,\"n_ctx\":2048,\"n_past\":706,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":20,\"tid\":\"132314544727616\",\"timestamp\":1710544452,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:14:12 | 200 |  1.363189815s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":30,\"tid\":\"132314544727616\",\"timestamp\":1710544452}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":829,\"slot_id\":0,\"task_id\":30,\"tid\":\"132314544727616\",\"timestamp\":1710544452}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":30,\"tid\":\"132314544727616\",\"timestamp\":1710544452}\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    1425.14 ms /   829 tokens (    1.72 ms per token,   581.70 tokens per second)\",\"n_prompt_tokens_processed\":829,\"n_tokens_second\":581.6988694412323,\"slot_id\":0,\"t_prompt_processing\":1425.136,\"t_token\":1.719102533172497,\"task_id\":30,\"tid\":\"132314544727616\",\"timestamp\":1710544454}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     139.95 ms /     7 runs   (   19.99 ms per token,    50.02 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":50.0189357399587,\"slot_id\":0,\"t_token\":19.992428571428572,\"t_token_generation\":139.947,\"task_id\":30,\"tid\":\"132314544727616\",\"timestamp\":1710544454}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    1565.08 ms\",\"slot_id\":0,\"t_prompt_processing\":1425.136,\"t_token_generation\":139.947,\"t_total\":1565.083,\"task_id\":30,\"tid\":\"132314544727616\",\"timestamp\":1710544454}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":875,\"n_ctx\":2048,\"n_past\":874,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":30,\"tid\":\"132314544727616\",\"timestamp\":1710544454,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:14:14 | 200 |   1.56916003s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":40,\"tid\":\"132314544727616\",\"timestamp\":1710544454}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":852,\"slot_id\":0,\"task_id\":40,\"tid\":\"132314544727616\",\"timestamp\":1710544454}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":40,\"tid\":\"132314544727616\",\"timestamp\":1710544454}\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    1549.84 ms /   852 tokens (    1.82 ms per token,   549.74 tokens per second)\",\"n_prompt_tokens_processed\":852,\"n_tokens_second\":549.7352302209845,\"slot_id\":0,\"t_prompt_processing\":1549.837,\"t_token\":1.8190575117370893,\"task_id\":40,\"tid\":\"132314544727616\",\"timestamp\":1710544456}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     140.61 ms /     7 runs   (   20.09 ms per token,    49.78 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":49.78202584398313,\"slot_id\":0,\"t_token\":20.08757142857143,\"t_token_generation\":140.613,\"task_id\":40,\"tid\":\"132314544727616\",\"timestamp\":1710544456}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    1690.45 ms\",\"slot_id\":0,\"t_prompt_processing\":1549.837,\"t_token_generation\":140.613,\"t_total\":1690.45,\"task_id\":40,\"tid\":\"132314544727616\",\"timestamp\":1710544456}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":898,\"n_ctx\":2048,\"n_past\":897,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":40,\"tid\":\"132314544727616\",\"timestamp\":1710544456,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:14:16 | 200 |  1.695739487s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "\"Node 'grade_documents':\"\n",
            "'\\n---\\n'\n",
            "---DECIDE TO GENERATE / SEARCH / TERMINATE---\n",
            "---DECISION: SIMILARITY SEARCH---\n",
            "---RETRIEVE---\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":50,\"tid\":\"132314544727616\",\"timestamp\":1710544456}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":624,\"slot_id\":0,\"task_id\":50,\"tid\":\"132314544727616\",\"timestamp\":1710544456}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":50,\"tid\":\"132314544727616\",\"timestamp\":1710544456}\n",
            "\"Node 'similarity_retrieve':\"\n",
            "'\\n---\\n'\n",
            "---CHECK RELEVANCE---\n",
            "Using Langchin to mount mistral:instruct with Ollama\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    1133.64 ms /   624 tokens (    1.82 ms per token,   550.44 tokens per second)\",\"n_prompt_tokens_processed\":624,\"n_tokens_second\":550.440263999619,\"slot_id\":0,\"t_prompt_processing\":1133.638,\"t_token\":1.816727564102564,\"task_id\":50,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     139.62 ms /     7 runs   (   19.95 ms per token,    50.14 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":50.1378791677112,\"slot_id\":0,\"t_token\":19.945,\"t_token_generation\":139.615,\"task_id\":50,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    1273.25 ms\",\"slot_id\":0,\"t_prompt_processing\":1133.638,\"t_token_generation\":139.615,\"t_total\":1273.253,\"task_id\":50,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":670,\"n_ctx\":2048,\"n_past\":669,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":50,\"tid\":\"132314544727616\",\"timestamp\":1710544457,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:14:17 | 200 |  1.278740285s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":60,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":663,\"n_past_se\":0,\"n_prompt_tokens_processed\":0,\"slot_id\":0,\"task_id\":60,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"we have to evaluate at least 1 token to generate logits\",\"slot_id\":0,\"task_id\":60,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":662,\"slot_id\":0,\"task_id\":60,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =      54.87 ms /     0 tokens (     inf ms per token,     0.00 tokens per second)\",\"n_prompt_tokens_processed\":0,\"n_tokens_second\":0.0,\"slot_id\":0,\"t_prompt_processing\":54.869,\"t_token\":null,\"task_id\":60,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     137.31 ms /     7 runs   (   19.62 ms per token,    50.98 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":50.97805030805308,\"slot_id\":0,\"t_token\":19.616285714285713,\"t_token_generation\":137.314,\"task_id\":60,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     192.18 ms\",\"slot_id\":0,\"t_prompt_processing\":54.869,\"t_token_generation\":137.314,\"t_total\":192.183,\"task_id\":60,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "[GIN] 2024/03/15 - 23:14:17 | 200 |  197.940996ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":670,\"n_ctx\":2048,\"n_past\":669,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":60,\"tid\":\"132314544727616\",\"timestamp\":1710544457,\"truncated\":false}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":70,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":663,\"n_past_se\":0,\"n_prompt_tokens_processed\":0,\"slot_id\":0,\"task_id\":70,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"we have to evaluate at least 1 token to generate logits\",\"slot_id\":0,\"task_id\":70,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":662,\"slot_id\":0,\"task_id\":70,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =      53.31 ms /     0 tokens (     inf ms per token,     0.00 tokens per second)\",\"n_prompt_tokens_processed\":0,\"n_tokens_second\":0.0,\"slot_id\":0,\"t_prompt_processing\":53.31,\"t_token\":null,\"task_id\":70,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     141.25 ms /     7 runs   (   20.18 ms per token,    49.56 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":49.55611876477835,\"slot_id\":0,\"t_token\":20.179142857142857,\"t_token_generation\":141.254,\"task_id\":70,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     194.56 ms\",\"slot_id\":0,\"t_prompt_processing\":53.31,\"t_token_generation\":141.254,\"t_total\":194.564,\"task_id\":70,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "[GIN] 2024/03/15 - 23:14:17 | 200 |  200.194484ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":670,\"n_ctx\":2048,\"n_past\":669,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":70,\"tid\":\"132314544727616\",\"timestamp\":1710544457,\"truncated\":false}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":80,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":663,\"n_past_se\":0,\"n_prompt_tokens_processed\":0,\"slot_id\":0,\"task_id\":80,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"we have to evaluate at least 1 token to generate logits\",\"slot_id\":0,\"task_id\":80,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":662,\"slot_id\":0,\"task_id\":80,\"tid\":\"132314544727616\",\"timestamp\":1710544457}\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =      55.88 ms /     0 tokens (     inf ms per token,     0.00 tokens per second)\",\"n_prompt_tokens_processed\":0,\"n_tokens_second\":0.0,\"slot_id\":0,\"t_prompt_processing\":55.881,\"t_token\":null,\"task_id\":80,\"tid\":\"132314544727616\",\"timestamp\":1710544458}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     138.80 ms /     7 runs   (   19.83 ms per token,    50.43 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":50.4308233192127,\"slot_id\":0,\"t_token\":19.82914285714286,\"t_token_generation\":138.804,\"task_id\":80,\"tid\":\"132314544727616\",\"timestamp\":1710544458}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     194.69 ms\",\"slot_id\":0,\"t_prompt_processing\":55.881,\"t_token_generation\":138.804,\"t_total\":194.685,\"task_id\":80,\"tid\":\"132314544727616\",\"timestamp\":1710544458}\n",
            "[GIN] 2024/03/15 - 23:14:18 | 200 |  197.924099ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":670,\"n_ctx\":2048,\"n_past\":669,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":80,\"tid\":\"132314544727616\",\"timestamp\":1710544458,\"truncated\":false}\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "\"Node 'grade_documents':\"\n",
            "'\\n---\\n'\n",
            "---DECIDE TO GENERATE / SEARCH / TERMINATE---\n",
            "---DECISION: TERMINATE SEARCH---\n",
            "---NO RELEVANT CONTEXT---\n",
            "\"Node 'terminate_search':\"\n",
            "'\\n---\\n'\n",
            "\"Node '__end__':\"\n",
            "'\\n---\\n'\n",
            "After performing both MRR & Similarity RAGs I couldn't find relevant context. can you please share more details in your question ?\n",
            "User entry - tell me about RISCV\n",
            "---RETRIEVE---\n",
            "\"Node 'mmr_retrieve':\"\n",
            "'\\n---\\n'\n",
            "---CHECK RELEVANCE---\n",
            "Using Langchin to mount mistral:instruct with Ollama\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":90,\"tid\":\"132314544727616\",\"timestamp\":1710544467}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":383,\"slot_id\":0,\"task_id\":90,\"tid\":\"132314544727616\",\"timestamp\":1710544467}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":90,\"tid\":\"132314544727616\",\"timestamp\":1710544467}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     764.25 ms /   383 tokens (    2.00 ms per token,   501.15 tokens per second)\",\"n_prompt_tokens_processed\":383,\"n_tokens_second\":501.1462247856716,\"slot_id\":0,\"t_prompt_processing\":764.248,\"t_token\":1.995425587467363,\"task_id\":90,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     132.21 ms /     7 runs   (   18.89 ms per token,    52.95 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":52.946070645185685,\"slot_id\":0,\"t_token\":18.88714285714286,\"t_token_generation\":132.21,\"task_id\":90,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     896.46 ms\",\"slot_id\":0,\"t_prompt_processing\":764.248,\"t_token_generation\":132.21,\"t_total\":896.4580000000001,\"task_id\":90,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":429,\"n_ctx\":2048,\"n_past\":428,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":90,\"tid\":\"132314544727616\",\"timestamp\":1710544468,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:14:28 | 200 |  901.856373ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":100,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":422,\"n_past_se\":0,\"n_prompt_tokens_processed\":0,\"slot_id\":0,\"task_id\":100,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"we have to evaluate at least 1 token to generate logits\",\"slot_id\":0,\"task_id\":100,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":421,\"slot_id\":0,\"task_id\":100,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =      40.02 ms /     0 tokens (     inf ms per token,     0.00 tokens per second)\",\"n_prompt_tokens_processed\":0,\"n_tokens_second\":0.0,\"slot_id\":0,\"t_prompt_processing\":40.024,\"t_token\":null,\"task_id\":100,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     129.01 ms /     7 runs   (   18.43 ms per token,    54.26 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":54.257256908111465,\"slot_id\":0,\"t_token\":18.430714285714284,\"t_token_generation\":129.015,\"task_id\":100,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     169.04 ms\",\"slot_id\":0,\"t_prompt_processing\":40.024,\"t_token_generation\":129.015,\"t_total\":169.039,\"task_id\":100,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "[GIN] 2024/03/15 - 23:14:28 | 200 |  173.154557ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":429,\"n_ctx\":2048,\"n_past\":428,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":100,\"tid\":\"132314544727616\",\"timestamp\":1710544468,\"truncated\":false}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":110,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":405,\"slot_id\":0,\"task_id\":110,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":110,\"tid\":\"132314544727616\",\"timestamp\":1710544468}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     735.74 ms /   405 tokens (    1.82 ms per token,   550.47 tokens per second)\",\"n_prompt_tokens_processed\":405,\"n_tokens_second\":550.4661972979585,\"slot_id\":0,\"t_prompt_processing\":735.74,\"t_token\":1.816641975308642,\"task_id\":110,\"tid\":\"132314544727616\",\"timestamp\":1710544469}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     137.36 ms /     7 runs   (   19.62 ms per token,    50.96 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":50.96023645549716,\"slot_id\":0,\"t_token\":19.623142857142856,\"t_token_generation\":137.362,\"task_id\":110,\"tid\":\"132314544727616\",\"timestamp\":1710544469}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     873.10 ms\",\"slot_id\":0,\"t_prompt_processing\":735.74,\"t_token_generation\":137.362,\"t_total\":873.102,\"task_id\":110,\"tid\":\"132314544727616\",\"timestamp\":1710544469}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":451,\"n_ctx\":2048,\"n_past\":450,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":110,\"tid\":\"132314544727616\",\"timestamp\":1710544469,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:14:29 | 200 |  877.139919ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":120,\"tid\":\"132314544727616\",\"timestamp\":1710544469}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":401,\"slot_id\":0,\"task_id\":120,\"tid\":\"132314544727616\",\"timestamp\":1710544469}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":120,\"tid\":\"132314544727616\",\"timestamp\":1710544469}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     727.73 ms /   401 tokens (    1.81 ms per token,   551.03 tokens per second)\",\"n_prompt_tokens_processed\":401,\"n_tokens_second\":551.0270264328077,\"slot_id\":0,\"t_prompt_processing\":727.732,\"t_token\":1.8147930174563591,\"task_id\":120,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     134.25 ms /     7 runs   (   19.18 ms per token,    52.14 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":52.1415270018622,\"slot_id\":0,\"t_token\":19.178571428571427,\"t_token_generation\":134.25,\"task_id\":120,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     861.98 ms\",\"slot_id\":0,\"t_prompt_processing\":727.732,\"t_token_generation\":134.25,\"t_total\":861.982,\"task_id\":120,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "[GIN] 2024/03/15 - 23:14:30 | 200 |  865.723281ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":447,\"n_ctx\":2048,\"n_past\":446,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":120,\"tid\":\"132314544727616\",\"timestamp\":1710544470,\"truncated\":false}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":130,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":289,\"slot_id\":0,\"task_id\":130,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":130,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     523.59 ms /   289 tokens (    1.81 ms per token,   551.96 tokens per second)\",\"n_prompt_tokens_processed\":289,\"n_tokens_second\":551.9638645110153,\"slot_id\":0,\"t_prompt_processing\":523.585,\"t_token\":1.8117128027681662,\"task_id\":130,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     131.05 ms /     7 runs   (   18.72 ms per token,    53.41 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":53.41431961602735,\"slot_id\":0,\"t_token\":18.721571428571426,\"t_token_generation\":131.051,\"task_id\":130,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     654.64 ms\",\"slot_id\":0,\"t_prompt_processing\":523.585,\"t_token_generation\":131.051,\"t_total\":654.636,\"task_id\":130,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "[GIN] 2024/03/15 - 23:14:30 | 200 |  658.363968ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":335,\"n_ctx\":2048,\"n_past\":334,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":130,\"tid\":\"132314544727616\",\"timestamp\":1710544470,\"truncated\":false}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "\"Node 'grade_documents':\"\n",
            "'\\n---\\n'\n",
            "---DECIDE TO GENERATE / SEARCH / TERMINATE---\n",
            "---DECISION: GENERATE---\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":140,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":4,\"n_past_se\":0,\"n_prompt_tokens_processed\":1657,\"slot_id\":0,\"task_id\":140,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":4,\"slot_id\":0,\"task_id\":140,\"tid\":\"132314544727616\",\"timestamp\":1710544470}\n",
            "---GENERATE---\n",
            "Using Langchin to mount mistral:instruct with Ollama\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    2980.38 ms /  1657 tokens (    1.80 ms per token,   555.97 tokens per second)\",\"n_prompt_tokens_processed\":1657,\"n_tokens_second\":555.9686268615052,\"slot_id\":0,\"t_prompt_processing\":2980.384,\"t_token\":1.7986626433313218,\"task_id\":140,\"tid\":\"132314544727616\",\"timestamp\":1710544477}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =    4098.98 ms /   156 runs   (   26.28 ms per token,    38.06 tokens per second)\",\"n_decoded\":156,\"n_tokens_second\":38.05828577674034,\"slot_id\":0,\"t_token\":26.27548717948718,\"t_token_generation\":4098.976,\"task_id\":140,\"tid\":\"132314544727616\",\"timestamp\":1710544477}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    7079.36 ms\",\"slot_id\":0,\"t_prompt_processing\":2980.384,\"t_token_generation\":4098.976,\"t_total\":7079.36,\"task_id\":140,\"tid\":\"132314544727616\",\"timestamp\":1710544477}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":1817,\"n_ctx\":2048,\"n_past\":1816,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":140,\"tid\":\"132314544727616\",\"timestamp\":1710544477,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:14:37 | 200 |  7.088367579s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "\"Node 'generate':\"\n",
            "'\\n---\\n'\n",
            "\"Node '__end__':\"\n",
            "'\\n---\\n'\n",
            " RISC-V is a new instruction set architecture (ISA) designed for computer architecture research and education, aiming to become a standard free and open architecture for industry implementations (Document, page 1). It was not designed to support the 2008 revision of the IEEE 754 floating-point standard (Document, page 1). The RISC-V ISA has gained significant uptake in both academia and industry since its introduction, leading to the creation of the non-profit RISC-V Foundation for its protection and promotion (Documents, pages 1-2). Unlike commercial ISAs, RISC-V is open and freely available to all. (Document, page 3)\n",
            "User entry - {\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":299,\"tid\":\"132314544727616\",\"timestamp\":1710544497}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":4,\"n_past_se\":0,\"n_prompt_tokens_processed\":341,\"slot_id\":0,\"task_id\":299,\"tid\":\"132314544727616\",\"timestamp\":1710544497}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":4,\"slot_id\":0,\"task_id\":299,\"tid\":\"132314544727616\",\"timestamp\":1710544497}\n",
            "list 10 special features of RISCV\n",
            "---RETRIEVE---\n",
            "\"Node 'mmr_retrieve':\"\n",
            "'\\n---\\n'\n",
            "---CHECK RELEVANCE---\n",
            "Using Langchin to mount mistral:instruct with Ollama\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     745.20 ms /   341 tokens (    2.19 ms per token,   457.59 tokens per second)\",\"n_prompt_tokens_processed\":341,\"n_tokens_second\":457.5946623796801,\"slot_id\":0,\"t_prompt_processing\":745.201,\"t_token\":2.1853401759530793,\"task_id\":299,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     131.89 ms /     7 runs   (   18.84 ms per token,    53.08 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":53.07533664927817,\"slot_id\":0,\"t_token\":18.84114285714286,\"t_token_generation\":131.888,\"task_id\":299,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     877.09 ms\",\"slot_id\":0,\"t_prompt_processing\":745.201,\"t_token_generation\":131.888,\"t_total\":877.089,\"task_id\":299,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":352,\"n_ctx\":2048,\"n_past\":351,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":299,\"tid\":\"132314544727616\",\"timestamp\":1710544498,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:14:58 | 200 |  881.622848ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":309,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":345,\"n_past_se\":0,\"n_prompt_tokens_processed\":0,\"slot_id\":0,\"task_id\":309,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"we have to evaluate at least 1 token to generate logits\",\"slot_id\":0,\"task_id\":309,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":344,\"slot_id\":0,\"task_id\":309,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =      40.40 ms /     0 tokens (     inf ms per token,     0.00 tokens per second)\",\"n_prompt_tokens_processed\":0,\"n_tokens_second\":0.0,\"slot_id\":0,\"t_prompt_processing\":40.4,\"t_token\":null,\"task_id\":309,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     131.42 ms /     7 runs   (   18.77 ms per token,    53.26 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":53.26353274185448,\"slot_id\":0,\"t_token\":18.774571428571427,\"t_token_generation\":131.422,\"task_id\":309,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     171.82 ms\",\"slot_id\":0,\"t_prompt_processing\":40.4,\"t_token_generation\":131.422,\"t_total\":171.822,\"task_id\":309,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":352,\"n_ctx\":2048,\"n_past\":351,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":309,\"tid\":\"132314544727616\",\"timestamp\":1710544498,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:14:58 | 200 |  176.025025ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":319,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":302,\"slot_id\":0,\"task_id\":319,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":319,\"tid\":\"132314544727616\",\"timestamp\":1710544498}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     537.97 ms /   302 tokens (    1.78 ms per token,   561.37 tokens per second)\",\"n_prompt_tokens_processed\":302,\"n_tokens_second\":561.3675061155599,\"slot_id\":0,\"t_prompt_processing\":537.972,\"t_token\":1.7813642384105959,\"task_id\":319,\"tid\":\"132314544727616\",\"timestamp\":1710544499}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     131.82 ms /     7 runs   (   18.83 ms per token,    53.10 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":53.103924380011684,\"slot_id\":0,\"t_token\":18.831,\"t_token_generation\":131.817,\"task_id\":319,\"tid\":\"132314544727616\",\"timestamp\":1710544499}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     669.79 ms\",\"slot_id\":0,\"t_prompt_processing\":537.972,\"t_token_generation\":131.817,\"t_total\":669.789,\"task_id\":319,\"tid\":\"132314544727616\",\"timestamp\":1710544499}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":348,\"n_ctx\":2048,\"n_past\":347,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":319,\"tid\":\"132314544727616\",\"timestamp\":1710544499,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:14:59 | 200 |  673.646302ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":329,\"tid\":\"132314544727616\",\"timestamp\":1710544499}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":588,\"slot_id\":0,\"task_id\":329,\"tid\":\"132314544727616\",\"timestamp\":1710544499}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":329,\"tid\":\"132314544727616\",\"timestamp\":1710544499}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    1130.41 ms /   588 tokens (    1.92 ms per token,   520.16 tokens per second)\",\"n_prompt_tokens_processed\":588,\"n_tokens_second\":520.1638693114817,\"slot_id\":0,\"t_prompt_processing\":1130.413,\"t_token\":1.9224710884353742,\"task_id\":329,\"tid\":\"132314544727616\",\"timestamp\":1710544500}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     136.08 ms /     7 runs   (   19.44 ms per token,    51.44 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":51.44070723623777,\"slot_id\":0,\"t_token\":19.439857142857143,\"t_token_generation\":136.079,\"task_id\":329,\"tid\":\"132314544727616\",\"timestamp\":1710544500}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    1266.49 ms\",\"slot_id\":0,\"t_prompt_processing\":1130.413,\"t_token_generation\":136.079,\"t_total\":1266.492,\"task_id\":329,\"tid\":\"132314544727616\",\"timestamp\":1710544500}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":634,\"n_ctx\":2048,\"n_past\":633,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":329,\"tid\":\"132314544727616\",\"timestamp\":1710544500,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:15:00 | 200 |  1.270658083s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":339,\"tid\":\"132314544727616\",\"timestamp\":1710544500}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":576,\"slot_id\":0,\"task_id\":339,\"tid\":\"132314544727616\",\"timestamp\":1710544500}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":339,\"tid\":\"132314544727616\",\"timestamp\":1710544500}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    1060.03 ms /   576 tokens (    1.84 ms per token,   543.38 tokens per second)\",\"n_prompt_tokens_processed\":576,\"n_tokens_second\":543.3834107686139,\"slot_id\":0,\"t_prompt_processing\":1060.025,\"t_token\":1.8403211805555557,\"task_id\":339,\"tid\":\"132314544727616\",\"timestamp\":1710544501}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     138.15 ms /     7 runs   (   19.74 ms per token,    50.67 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":50.66919530079405,\"slot_id\":0,\"t_token\":19.735857142857146,\"t_token_generation\":138.151,\"task_id\":339,\"tid\":\"132314544727616\",\"timestamp\":1710544501}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    1198.18 ms\",\"slot_id\":0,\"t_prompt_processing\":1060.025,\"t_token_generation\":138.151,\"t_total\":1198.1760000000002,\"task_id\":339,\"tid\":\"132314544727616\",\"timestamp\":1710544501}\n",
            "[GIN] 2024/03/15 - 23:15:01 | 200 |  1.201906777s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":622,\"n_ctx\":2048,\"n_past\":621,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":339,\"tid\":\"132314544727616\",\"timestamp\":1710544501,\"truncated\":false}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":349,\"tid\":\"132314544727616\",\"timestamp\":1710544502}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":4,\"n_past_se\":0,\"n_prompt_tokens_processed\":1914,\"slot_id\":0,\"task_id\":349,\"tid\":\"132314544727616\",\"timestamp\":1710544502}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":4,\"slot_id\":0,\"task_id\":349,\"tid\":\"132314544727616\",\"timestamp\":1710544502}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "\"Node 'grade_documents':\"\n",
            "'\\n---\\n'\n",
            "---DECIDE TO GENERATE / SEARCH / TERMINATE---\n",
            "---DECISION: GENERATE---\n",
            "---GENERATE---\n",
            "Using Langchin to mount mistral:instruct with Ollama\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1613,\"msg\":\"slot context shift\",\"n_cache_tokens\":2048,\"n_ctx\":2048,\"n_discard\":1023,\"n_keep\":1,\"n_left\":2046,\"n_past\":2047,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":349,\"tid\":\"132314544727616\",\"timestamp\":1710544509}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    3481.50 ms /  1914 tokens (    1.82 ms per token,   549.76 tokens per second)\",\"n_prompt_tokens_processed\":1914,\"n_tokens_second\":549.7625594463082,\"slot_id\":0,\"t_prompt_processing\":3481.503,\"t_token\":1.8189670846394985,\"task_id\":349,\"tid\":\"132314544727616\",\"timestamp\":1710544513}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =    8021.72 ms /   296 runs   (   27.10 ms per token,    36.90 tokens per second)\",\"n_decoded\":296,\"n_tokens_second\":36.89982159684227,\"slot_id\":0,\"t_token\":27.100402027027027,\"t_token_generation\":8021.719,\"task_id\":349,\"tid\":\"132314544727616\",\"timestamp\":1710544513}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =   11503.22 ms\",\"slot_id\":0,\"t_prompt_processing\":3481.503,\"t_token_generation\":8021.719,\"t_total\":11503.222,\"task_id\":349,\"tid\":\"132314544727616\",\"timestamp\":1710544513}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":1191,\"n_ctx\":2048,\"n_past\":1190,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":349,\"tid\":\"132314544727616\",\"timestamp\":1710544513,\"truncated\":true}\n",
            "[GIN] 2024/03/15 - 23:15:13 | 200 | 11.510761677s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "\"Node 'generate':\"\n",
            "'\\n---\\n'\n",
            "\"Node '__end__':\"\n",
            "'\\n---\\n'\n",
            " Based on the provided context, here are ten special features of RISC-V as described in the documents:\n",
            "\n",
            "1. Extensible ISA: RISC-V can be extended with optional instruction-set extensions.\n",
            "2. Customizable: The base integer ISA is designed for extensive customization and specialization.\n",
            "3. Standard and non-standard extensions: Instruction-set extensions are divided into standard and non-standard categories.\n",
            "4. Flexible: The user-level manual aims to remove dependence on microarchitectural features or privileged architecture details.\n",
            "5. Base integer ISA: RISC-V has a base integer instruction set for 32-bit (RV32) and 64-bit (RV64) formats.\n",
            "6. User-level interrupts: The N extension supports user-level interrupts with additional CSRs and instructions.\n",
            "7. Rapid configuration instructions: Vector extensions support rapid configuration instructions.\n",
            "8. Reducing context-swap overhead: RISC-V includes features to reduce context-swap overhead.\n",
            "9. VLIW encodings: The documents discuss adding aligned 64-bit instruction extensions and supporting Very Long Instruction Word (VLIW) encodings.\n",
            "10. Extension design philosophy: The extension design philosophy is discussed, emphasizing the importance of backward compatibility and extensibility.\n",
            "User entry - list all of RISCV ISA\n",
            "---RETRIEVE---\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":648,\"tid\":\"132314544727616\",\"timestamp\":1710544536}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":1,\"n_past_se\":0,\"n_prompt_tokens_processed\":705,\"slot_id\":0,\"task_id\":648,\"tid\":\"132314544727616\",\"timestamp\":1710544536}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":1,\"slot_id\":0,\"task_id\":648,\"tid\":\"132314544727616\",\"timestamp\":1710544536}\n",
            "\"Node 'mmr_retrieve':\"\n",
            "'\\n---\\n'\n",
            "---CHECK RELEVANCE---\n",
            "Using Langchin to mount mistral:instruct with Ollama\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    1488.63 ms /   705 tokens (    2.11 ms per token,   473.59 tokens per second)\",\"n_prompt_tokens_processed\":705,\"n_tokens_second\":473.5901289038438,\"slot_id\":0,\"t_prompt_processing\":1488.629,\"t_token\":2.111530496453901,\"task_id\":648,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     146.21 ms /     7 runs   (   20.89 ms per token,    47.88 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":47.87634224745229,\"slot_id\":0,\"t_token\":20.88714285714286,\"t_token_generation\":146.21,\"task_id\":648,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    1634.84 ms\",\"slot_id\":0,\"t_prompt_processing\":1488.629,\"t_token_generation\":146.21,\"t_total\":1634.839,\"task_id\":648,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":713,\"n_ctx\":2048,\"n_past\":712,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":648,\"tid\":\"132314544727616\",\"timestamp\":1710544538,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:15:38 | 200 |  1.640658898s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":658,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":706,\"n_past_se\":0,\"n_prompt_tokens_processed\":0,\"slot_id\":0,\"task_id\":658,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"we have to evaluate at least 1 token to generate logits\",\"slot_id\":0,\"task_id\":658,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":705,\"slot_id\":0,\"task_id\":658,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =      60.41 ms /     0 tokens (     inf ms per token,     0.00 tokens per second)\",\"n_prompt_tokens_processed\":0,\"n_tokens_second\":0.0,\"slot_id\":0,\"t_prompt_processing\":60.41,\"t_token\":null,\"task_id\":658,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     144.64 ms /     7 runs   (   20.66 ms per token,    48.40 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":48.39501393085044,\"slot_id\":0,\"t_token\":20.663285714285713,\"t_token_generation\":144.643,\"task_id\":658,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     205.05 ms\",\"slot_id\":0,\"t_prompt_processing\":60.41,\"t_token_generation\":144.643,\"t_total\":205.053,\"task_id\":658,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "[GIN] 2024/03/15 - 23:15:38 | 200 |  210.812598ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":713,\"n_ctx\":2048,\"n_past\":712,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":658,\"tid\":\"132314544727616\",\"timestamp\":1710544538,\"truncated\":false}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":668,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":364,\"slot_id\":0,\"task_id\":668,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":668,\"tid\":\"132314544727616\",\"timestamp\":1710544538}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     684.84 ms /   364 tokens (    1.88 ms per token,   531.51 tokens per second)\",\"n_prompt_tokens_processed\":364,\"n_tokens_second\":531.5094576559266,\"slot_id\":0,\"t_prompt_processing\":684.842,\"t_token\":1.8814340659340658,\"task_id\":668,\"tid\":\"132314544727616\",\"timestamp\":1710544539}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     143.69 ms /     7 runs   (   20.53 ms per token,    48.72 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":48.71666388285731,\"slot_id\":0,\"t_token\":20.526857142857143,\"t_token_generation\":143.688,\"task_id\":668,\"tid\":\"132314544727616\",\"timestamp\":1710544539}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     828.53 ms\",\"slot_id\":0,\"t_prompt_processing\":684.842,\"t_token_generation\":143.688,\"t_total\":828.53,\"task_id\":668,\"tid\":\"132314544727616\",\"timestamp\":1710544539}\n",
            "[GIN] 2024/03/15 - 23:15:39 | 200 |  838.427576ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":410,\"n_ctx\":2048,\"n_past\":409,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":668,\"tid\":\"132314544727616\",\"timestamp\":1710544539,\"truncated\":false}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":678,\"tid\":\"132314544727616\",\"timestamp\":1710544539}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":300,\"slot_id\":0,\"task_id\":678,\"tid\":\"132314544727616\",\"timestamp\":1710544539}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":678,\"tid\":\"132314544727616\",\"timestamp\":1710544539}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     569.96 ms /   300 tokens (    1.90 ms per token,   526.35 tokens per second)\",\"n_prompt_tokens_processed\":300,\"n_tokens_second\":526.3508795323197,\"slot_id\":0,\"t_prompt_processing\":569.962,\"t_token\":1.8998733333333333,\"task_id\":678,\"tid\":\"132314544727616\",\"timestamp\":1710544540}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     139.59 ms /     7 runs   (   19.94 ms per token,    50.15 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":50.145780948901454,\"slot_id\":0,\"t_token\":19.941857142857142,\"t_token_generation\":139.593,\"task_id\":678,\"tid\":\"132314544727616\",\"timestamp\":1710544540}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     709.55 ms\",\"slot_id\":0,\"t_prompt_processing\":569.962,\"t_token_generation\":139.593,\"t_total\":709.555,\"task_id\":678,\"tid\":\"132314544727616\",\"timestamp\":1710544540}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":346,\"n_ctx\":2048,\"n_past\":345,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":678,\"tid\":\"132314544727616\",\"timestamp\":1710544540,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:15:40 | 200 |   716.58755ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":688,\"tid\":\"132314544727616\",\"timestamp\":1710544540}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":361,\"slot_id\":0,\"task_id\":688,\"tid\":\"132314544727616\",\"timestamp\":1710544540}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":688,\"tid\":\"132314544727616\",\"timestamp\":1710544540}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     691.53 ms /   361 tokens (    1.92 ms per token,   522.03 tokens per second)\",\"n_prompt_tokens_processed\":361,\"n_tokens_second\":522.0293493287368,\"slot_id\":0,\"t_prompt_processing\":691.532,\"t_token\":1.9156011080332411,\"task_id\":688,\"tid\":\"132314544727616\",\"timestamp\":1710544541}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     137.22 ms /     7 runs   (   19.60 ms per token,    51.01 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":51.01445895522388,\"slot_id\":0,\"t_token\":19.602285714285717,\"t_token_generation\":137.216,\"task_id\":688,\"tid\":\"132314544727616\",\"timestamp\":1710544541}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     828.75 ms\",\"slot_id\":0,\"t_prompt_processing\":691.532,\"t_token_generation\":137.216,\"t_total\":828.748,\"task_id\":688,\"tid\":\"132314544727616\",\"timestamp\":1710544541}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":407,\"n_ctx\":2048,\"n_past\":406,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":688,\"tid\":\"132314544727616\",\"timestamp\":1710544541,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:15:41 | 200 |  835.576043ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":698,\"tid\":\"132314544727616\",\"timestamp\":1710544541}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":0,\"n_past_se\":0,\"n_prompt_tokens_processed\":1186,\"slot_id\":0,\"task_id\":698,\"tid\":\"132314544727616\",\"timestamp\":1710544541}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":0,\"slot_id\":0,\"task_id\":698,\"tid\":\"132314544727616\",\"timestamp\":1710544541}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "\"Node 'grade_documents':\"\n",
            "'\\n---\\n'\n",
            "---DECIDE TO GENERATE / SEARCH / TERMINATE---\n",
            "---DECISION: GENERATE---\n",
            "---GENERATE---\n",
            "Using Langchin to mount mistral:instruct with Ollama\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    2187.12 ms /  1186 tokens (    1.84 ms per token,   542.27 tokens per second)\",\"n_prompt_tokens_processed\":1186,\"n_tokens_second\":542.2666196031669,\"slot_id\":0,\"t_prompt_processing\":2187.116,\"t_token\":1.8441112984822934,\"task_id\":698,\"tid\":\"132314544727616\",\"timestamp\":1710544549}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =    6627.41 ms /   255 runs   (   25.99 ms per token,    38.48 tokens per second)\",\"n_decoded\":255,\"n_tokens_second\":38.47657508386762,\"slot_id\":0,\"t_token\":25.989839215686274,\"t_token_generation\":6627.409,\"task_id\":698,\"tid\":\"132314544727616\",\"timestamp\":1710544549}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    8814.52 ms\",\"slot_id\":0,\"t_prompt_processing\":2187.116,\"t_token_generation\":6627.409,\"t_total\":8814.525,\"task_id\":698,\"tid\":\"132314544727616\",\"timestamp\":1710544549}\n",
            "[GIN] 2024/03/15 - 23:15:49 | 200 |  8.826302332s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":1441,\"n_ctx\":2048,\"n_past\":1440,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":698,\"tid\":\"132314544727616\",\"timestamp\":1710544549,\"truncated\":true}\n",
            "\"Node 'generate':\"\n",
            "'\\n---\\n'\n",
            "\"Node '__end__':\"\n",
            "'\\n---\\n'\n",
            " The RISC-V Instruction Set Architecture (ISA) is modular and can include a base integer ISA along with various optional extensions. The base integer ISA comes in different sizes: 32-bit (RV32I), 32-bit floating point (RV32E), 64-bit (RV64I), or 128-bit (RV128I). Some common instruction set extensions include Atomic (RAtomic), Compressed (RC), Multiple Access Fetch and Decode (M), Double Precision Floating Point (FD), and Integer Multiplication and Division (IM).\n",
            "\n",
            "So, a complete list of RISC-V ISAs would look like:\n",
            "\n",
            "* RV32I\n",
            "* RV32E\n",
            "* RV64I\n",
            "* RV128I\n",
            "* RAtomic\n",
            "* RC\n",
            "* M\n",
            "* FD\n",
            "* IM\n",
            "\n",
            "Each of these ISAs can be further customized by including additional extensions. For example, a system might include RV64I with the Atomic and Compressed extensions (RV64I-C-RAtomic).\n",
            "User entry - does RISCV support VLIW ?\n",
            "---RETRIEVE---\n",
            "\"Node 'mmr_retrieve':\"\n",
            "'\\n---\\n'\n",
            "---CHECK RELEVANCE---\n",
            "Using Langchin to mount mistral:instruct with Ollama\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":956,\"tid\":\"132314544727616\",\"timestamp\":1710544577}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":0,\"n_past_se\":0,\"n_prompt_tokens_processed\":387,\"slot_id\":0,\"task_id\":956,\"tid\":\"132314544727616\",\"timestamp\":1710544577}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":0,\"slot_id\":0,\"task_id\":956,\"tid\":\"132314544727616\",\"timestamp\":1710544577}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     849.59 ms /   387 tokens (    2.20 ms per token,   455.52 tokens per second)\",\"n_prompt_tokens_processed\":387,\"n_tokens_second\":455.5154445630642,\"slot_id\":0,\"t_prompt_processing\":849.587,\"t_token\":2.195315245478036,\"task_id\":956,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     135.31 ms /     7 runs   (   19.33 ms per token,    51.73 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":51.731145844880466,\"slot_id\":0,\"t_token\":19.330714285714286,\"t_token_generation\":135.315,\"task_id\":956,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     984.90 ms\",\"slot_id\":0,\"t_prompt_processing\":849.587,\"t_token_generation\":135.315,\"t_total\":984.902,\"task_id\":956,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":394,\"n_ctx\":2048,\"n_past\":393,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":956,\"tid\":\"132314544727616\",\"timestamp\":1710544578,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:16:18 | 200 |  991.040926ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":966,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":387,\"n_past_se\":0,\"n_prompt_tokens_processed\":0,\"slot_id\":0,\"task_id\":966,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"we have to evaluate at least 1 token to generate logits\",\"slot_id\":0,\"task_id\":966,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":386,\"slot_id\":0,\"task_id\":966,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =      41.89 ms /     0 tokens (     inf ms per token,     0.00 tokens per second)\",\"n_prompt_tokens_processed\":0,\"n_tokens_second\":0.0,\"slot_id\":0,\"t_prompt_processing\":41.892,\"t_token\":null,\"task_id\":966,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     137.43 ms /     7 runs   (   19.63 ms per token,    50.93 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":50.93353900781466,\"slot_id\":0,\"t_token\":19.63342857142857,\"t_token_generation\":137.434,\"task_id\":966,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     179.33 ms\",\"slot_id\":0,\"t_prompt_processing\":41.892,\"t_token_generation\":137.434,\"t_total\":179.326,\"task_id\":966,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":394,\"n_ctx\":2048,\"n_past\":393,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":966,\"tid\":\"132314544727616\",\"timestamp\":1710544578,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:16:18 | 200 |  183.852361ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":976,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":375,\"slot_id\":0,\"task_id\":976,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":976,\"tid\":\"132314544727616\",\"timestamp\":1710544578}\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     685.33 ms /   375 tokens (    1.83 ms per token,   547.18 tokens per second)\",\"n_prompt_tokens_processed\":375,\"n_tokens_second\":547.1840449887426,\"slot_id\":0,\"t_prompt_processing\":685.327,\"t_token\":1.8275386666666666,\"task_id\":976,\"tid\":\"132314544727616\",\"timestamp\":1710544579}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     144.59 ms /     7 runs   (   20.66 ms per token,    48.41 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":48.41141402824461,\"slot_id\":0,\"t_token\":20.656285714285712,\"t_token_generation\":144.594,\"task_id\":976,\"tid\":\"132314544727616\",\"timestamp\":1710544579}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =     829.92 ms\",\"slot_id\":0,\"t_prompt_processing\":685.327,\"t_token_generation\":144.594,\"t_total\":829.921,\"task_id\":976,\"tid\":\"132314544727616\",\"timestamp\":1710544579}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":421,\"n_ctx\":2048,\"n_past\":420,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":976,\"tid\":\"132314544727616\",\"timestamp\":1710544579,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:16:19 | 200 |  833.540015ms |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":986,\"tid\":\"132314544727616\",\"timestamp\":1710544579}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":546,\"slot_id\":0,\"task_id\":986,\"tid\":\"132314544727616\",\"timestamp\":1710544579}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":986,\"tid\":\"132314544727616\",\"timestamp\":1710544579}\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    1073.48 ms /   546 tokens (    1.97 ms per token,   508.63 tokens per second)\",\"n_prompt_tokens_processed\":546,\"n_tokens_second\":508.62709808677954,\"slot_id\":0,\"t_prompt_processing\":1073.478,\"t_token\":1.9660769230769233,\"task_id\":986,\"tid\":\"132314544727616\",\"timestamp\":1710544580}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     143.68 ms /     7 runs   (   20.53 ms per token,    48.72 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":48.720054566461116,\"slot_id\":0,\"t_token\":20.52542857142857,\"t_token_generation\":143.678,\"task_id\":986,\"tid\":\"132314544727616\",\"timestamp\":1710544580}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    1217.16 ms\",\"slot_id\":0,\"t_prompt_processing\":1073.478,\"t_token_generation\":143.678,\"t_total\":1217.156,\"task_id\":986,\"tid\":\"132314544727616\",\"timestamp\":1710544580}\n",
            "[GIN] 2024/03/15 - 23:16:20 | 200 |  1.221632433s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":592,\"n_ctx\":2048,\"n_past\":591,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":986,\"tid\":\"132314544727616\",\"timestamp\":1710544580,\"truncated\":false}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":996,\"tid\":\"132314544727616\",\"timestamp\":1710544580}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":39,\"n_past_se\":0,\"n_prompt_tokens_processed\":519,\"slot_id\":0,\"task_id\":996,\"tid\":\"132314544727616\",\"timestamp\":1710544580}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":996,\"tid\":\"132314544727616\",\"timestamp\":1710544580}\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =     986.46 ms /   519 tokens (    1.90 ms per token,   526.12 tokens per second)\",\"n_prompt_tokens_processed\":519,\"n_tokens_second\":526.1226484142319,\"slot_id\":0,\"t_prompt_processing\":986.462,\"t_token\":1.9006974951830442,\"task_id\":996,\"tid\":\"132314544727616\",\"timestamp\":1710544581}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =     142.16 ms /     7 runs   (   20.31 ms per token,    49.24 tokens per second)\",\"n_decoded\":7,\"n_tokens_second\":49.24098538246177,\"slot_id\":0,\"t_token\":20.308285714285713,\"t_token_generation\":142.158,\"task_id\":996,\"tid\":\"132314544727616\",\"timestamp\":1710544581}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    1128.62 ms\",\"slot_id\":0,\"t_prompt_processing\":986.462,\"t_token_generation\":142.158,\"t_total\":1128.62,\"task_id\":996,\"tid\":\"132314544727616\",\"timestamp\":1710544581}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":565,\"n_ctx\":2048,\"n_past\":564,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":996,\"tid\":\"132314544727616\",\"timestamp\":1710544581,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:16:21 | 200 |  1.133338088s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":1006,\"tid\":\"132314544727616\",\"timestamp\":1710544581}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1821,\"msg\":\"slot progression\",\"n_past\":4,\"n_past_se\":0,\"n_prompt_tokens_processed\":724,\"slot_id\":0,\"task_id\":1006,\"tid\":\"132314544727616\",\"timestamp\":1710544581}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1848,\"msg\":\"kv cache rm [p0, end)\",\"p0\":4,\"slot_id\":0,\"task_id\":1006,\"tid\":\"132314544727616\",\"timestamp\":1710544581}\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "\"Node 'grade_documents':\"\n",
            "'\\n---\\n'\n",
            "---DECIDE TO GENERATE / SEARCH / TERMINATE---\n",
            "---DECISION: GENERATE---\n",
            "---GENERATE---\n",
            "Using Langchin to mount mistral:instruct with Ollama\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":257,\"msg\":\"prompt eval time     =    1366.23 ms /   724 tokens (    1.89 ms per token,   529.93 tokens per second)\",\"n_prompt_tokens_processed\":724,\"n_tokens_second\":529.9269666951149,\"slot_id\":0,\"t_prompt_processing\":1366.226,\"t_token\":1.8870524861878455,\"task_id\":1006,\"tid\":\"132314544727616\",\"timestamp\":1710544588}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":271,\"msg\":\"generation eval time =    5380.35 ms /   209 runs   (   25.74 ms per token,    38.85 tokens per second)\",\"n_decoded\":209,\"n_tokens_second\":38.84509264740458,\"slot_id\":0,\"t_token\":25.743277511961725,\"t_token_generation\":5380.345,\"task_id\":1006,\"tid\":\"132314544727616\",\"timestamp\":1710544588}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":281,\"msg\":\"          total time =    6746.57 ms\",\"slot_id\":0,\"t_prompt_processing\":1366.226,\"t_token_generation\":5380.345,\"t_total\":6746.571,\"task_id\":1006,\"tid\":\"132314544727616\",\"timestamp\":1710544588}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1652,\"msg\":\"slot released\",\"n_cache_tokens\":937,\"n_ctx\":2048,\"n_past\":936,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":1006,\"tid\":\"132314544727616\",\"timestamp\":1710544588,\"truncated\":false}\n",
            "[GIN] 2024/03/15 - 23:16:28 | 200 |  6.754583223s |       127.0.0.1 | POST     \"/api/chat\"\n",
            "\"Node 'generate':\"\n",
            "'\\n---\\n'\n",
            "\"Node '__end__':\"\n",
            "'\\n---\\n'\n",
            " According to the provided context from the RISC-V specification document, VLIW (Very Long Instruction Word) encodings can be added as extensions to RISC-V using approaches that include defining a single large naturally aligned instruction format for VLIW operations or using encoded-length groups. However, the base 32-bit encoding must always be supported in order to use standard software tools (Refer to pages with content 'We anticipate processor generators that produce instruction-fetch units capable of automatically handling any combination of supported variable-length instruction encodings' and 'Although RISC-V was not designed as a base for a pure VLIW machine, VLIW encodings can be added as extensions using several alternative approaches. In all cases, the base 32-bit encoding has to be supported to allow use of any standard software tools.' in the document). Therefore, RISC-V does support VLIW encodings as an extension.\n",
            "User entry - \n"
          ]
        }
      ],
      "source": [
        "!python GPTme/Examples/crag_example.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lPyyJzqY8md"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyML1q7LtddtRyNg6Jx2A/nb",
      "collapsed_sections": [
        "tWNkF7vsAY8r"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
